# -*- coding: utf-8 -*-

import requests
import bs4
import hashlib
from utils import get_seen_hashes, message_to_hash, summarize_text_with_hf

def get_page_content(url):
    """URLì„ ì…ë ¥ë°›ì•„, ì›¹ í˜ì´ì§€ì˜ ë³¸ë¬¸ í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œí•˜ì—¬ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜"""
    print(f"í˜ì´ì§€ ë‚´ìš© ì¶”ì¶œ ì‹œë„: {url}")
    try:
        response = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'}, timeout=30)
        response.raise_for_status()
        soup = bs4.BeautifulSoup(response.text, 'lxml')
        content_area = soup.select_one('.view-content') or soup.select_one('.board_view_content')
        if content_area:
            return content_area.get_text(separator="\n", strip=True)
        print("ì˜¤ë¥˜: ë³¸ë¬¸ ì˜ì—­ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None
    except requests.exceptions.RequestException as e:
        print(f"ì˜¤ë¥˜: í˜ì´ì§€ ë‚´ìš©ì„ ê°€ì ¸ì˜¤ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤ - {e}")
        return None

async def fetch_and_process_news(api_url, seen_file, hf_token):
    """APIë¥¼ í†µí•´ ìƒˆë¡œìš´ ê³µì§€ì‚¬í•­ì„ ê°€ì ¸ì™€ ì²˜ë¦¬í•˜ê³ , ë³´ë‚¼ ë©”ì‹œì§€ ëª©ë¡ê³¼ ìƒˆë¡œìš´ í•´ì‹œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    print("1. ê³µì§€ì‚¬í•­ APIì— ì ‘ì†í•©ë‹ˆë‹¤...")
    try:
        response = requests.post(api_url, headers={'User-Agent': 'Mozilla/5.0'})
        response.raise_for_status()
    except requests.exceptions.RequestException as e:
        print(f"APIì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
        return [], []

    print("2. API ì‘ë‹µ HTMLì„ íŒŒì‹±í•©ë‹ˆë‹¤...")
    soup = bs4.BeautifulSoup(response.text, "html.parser")
    links = soup.select("td.td-subject > a")
    
    print(f"3. ë°œê²¬ëœ ê²Œì‹œë¬¼ ë§í¬ ìˆ˜: {len(links)}ê°œ")
    if not links:
        print("-> ê²Œì‹œë¬¼ ë§í¬ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        return [], []

    seen_hashes = get_seen_hashes(seen_file)
    new_hashes = []
    messages_to_send = []

    for link_element in reversed(links):
        title = ' '.join(link_element.text.strip().split())
        link = link_element.get("href")
        
        if not link or not title or "javascript:void(0)" in link:
            continue
        
        try:
            artcl_id = link.split("/")[-2]
            id_hash = message_to_hash(artcl_id)
        except IndexError:
            print(f"ê²½ê³ : ë§í¬ í˜•ì‹ ì˜¤ë¥˜ë¡œ IDë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {link}")
            id_hash = message_to_hash(title)

        if id_hash in seen_hashes:
            continue

        full_link = f"https://www.knou.ac.kr{link}"
        
        print(f"\n4. ì²˜ë¦¬ ì¤‘ì¸ ê²Œì‹œë¬¼: {title}")
        content = get_page_content(full_link)
        summary = summarize_text_with_hf(content, hf_token)
        
        message = (
            f"ğŸ“Œ **{title}**\n\n"
            f"ğŸ“ **ë‚´ìš© ìš”ì•½:**\n{summary}\n\n"
            f"ğŸ”— **ì›ë¬¸ ë§í¬:**\n{full_link}"
        )
        messages_to_send.append(message)
        new_hashes.append(id_hash)

    return messages_to_send, new_hashes
